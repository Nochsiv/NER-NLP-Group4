{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], ['[CLS]', 'I', 'am', 'a', 'student', 'Natural', 'Lang', '##au', '##ge', 'Process', '##ing', 'is', 'a', 'good', 'course', '[SEP]'])\n"
     ]
    }
   ],
   "source": [
    "from bi_lstm_crf_predictor import BiLSTM_CRF_Predictor\n",
    "predictor = BiLSTM_CRF_Predictor()\n",
    "print(predictor.prediction(\"I am a student Natural Langauge Processing is a good course\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90ce8831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1, 1, 1, 1, 1, 1], ['[CLS]', 'I', 'am', 'a', 'student', '[SEP]'])\n"
     ]
    }
   ],
   "source": [
    "print(predictor.prediction(\"I am a student\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6d12e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForTokenClassification, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-large-NER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "724b5b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 6240, 12431, 3984, 2176, 18821, 1158, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"Natural Langauge Processing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a731b659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 146, 1821, 170, 2377, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'I', 'am', 'a', 'student', '[SEP]']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fe = tokenizer(\"I am a student\")\n",
    "# number to word\n",
    "print(fe)\n",
    "tokenizer.convert_ids_to_tokens([ 101,  146, 1821,  170, 2377,  102])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae347d09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf4ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Hello, my name is John Doe. I am a student at the University of California, Berkeley. I am studying computer science. I am interested in natural language processing. I am working on a project that involves named entity recognition. I am using a BiLSTM-CRF model for this project. I am excited to see the results of my project.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "286ce7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], ['[CLS]', 'Hello', ',', 'my', 'name', 'is', 'John', 'Do', '##e', '.', 'I', 'am', 'a', 'student', 'at', 'the', 'University', 'of', 'California', ',', 'Berkeley', '.', 'I', 'am', 'studying', 'computer', 'science', '.', 'I', 'am', 'interested', 'in', 'natural', 'language', 'processing', '.', 'I', 'am', 'working', 'on', 'a', 'project', 'that', 'involves', 'named', 'entity', 'recognition', '.', 'I', 'am', 'using', 'a', 'B', '##i', '##LS', '##TM', '-', 'CR', '##F', 'model', 'for', 'this', 'project', '.', 'I', 'am', 'excited', 'to', 'see', 'the', 'results', 'of', 'my', 'project', '.', '[SEP]'])\n"
     ]
    }
   ],
   "source": [
    "print(predictor.prediction(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cd43e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76\n"
     ]
    }
   ],
   "source": [
    "print(len(predictor.prediction(sentence)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf18d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "28,20-48,40-58"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cc0a7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[28, 28, 2]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(sen) for sen in list_of_sentences]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
